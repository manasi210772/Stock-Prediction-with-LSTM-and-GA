{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e3b8b177-1cec-4d0d-9f9e-ef1c18094d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89470a61-2e51-4ad7-93bf-d92b6c7a2a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GAHyperparams:\n",
    "    \"\"\"Hyperparameter configuration for LSTM model\"\"\"\n",
    "    sequence_length: int\n",
    "    hidden_size: int\n",
    "    num_layers: int\n",
    "    dropout: float\n",
    "    learning_rate: float\n",
    "    batch_size: int\n",
    "    epochs: int\n",
    "\n",
    "    def to_dict(self) -> Dict:\n",
    "        return {\n",
    "            'sequence_length': self.sequence_length,\n",
    "            'hidden_size': self.hidden_size,\n",
    "            'num_layers': self.num_layers,\n",
    "            'dropout': self.dropout,\n",
    "            'learning_rate': self.learning_rate,\n",
    "            'batch_size': self.batch_size,\n",
    "            'epochs': self.epochs\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "befbde6d-077d-4b21-b26a-40ef1ce3d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    \"\"\"LSTM Cell implemented from scratch\"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Weight matrices for input-to-hidden connections\n",
    "        self.W_ii = nn.Parameter(torch.randn(hidden_size, input_size))\n",
    "        self.W_if = nn.Parameter(torch.randn(hidden_size, input_size))\n",
    "        self.W_ig = nn.Parameter(torch.randn(hidden_size, input_size))\n",
    "        self.W_io = nn.Parameter(torch.randn(hidden_size, input_size))\n",
    "\n",
    "        # Weight matrices for hidden-to-hidden connections\n",
    "        self.W_hi = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "        self.W_hf = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "        self.W_hg = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "        self.W_ho = nn.Parameter(torch.randn(hidden_size, hidden_size))\n",
    "\n",
    "        # Bias vectors\n",
    "        self.b_i = nn.Parameter(torch.randn(hidden_size))\n",
    "        self.b_f = nn.Parameter(torch.randn(hidden_size))\n",
    "        self.b_g = nn.Parameter(torch.randn(hidden_size))\n",
    "        self.b_o = nn.Parameter(torch.randn(hidden_size))\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"Initialize weights using Xavier initialization\"\"\"\n",
    "        std = 1.0 / (self.hidden_size)**0.5\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-std, std)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        h_prev, c_prev = hidden\n",
    "\n",
    "        # Input gate\n",
    "        i_t = torch.sigmoid(torch.mm(self.W_ii, x.t()) + torch.mm(self.W_hi, h_prev.t()) + self.b_i.unsqueeze(1))\n",
    "\n",
    "        # Forget gate\n",
    "        f_t = torch.sigmoid(torch.mm(self.W_if, x.t()) + torch.mm(self.W_hf, h_prev.t()) + self.b_f.unsqueeze(1))\n",
    "\n",
    "        # Cell gate (candidate values)\n",
    "        g_t = torch.tanh(torch.mm(self.W_ig, x.t()) + torch.mm(self.W_hg, h_prev.t()) + self.b_g.unsqueeze(1))\n",
    "\n",
    "        # Output gate\n",
    "        o_t = torch.sigmoid(torch.mm(self.W_io, x.t()) + torch.mm(self.W_ho, h_prev.t()) + self.b_o.unsqueeze(1))\n",
    "\n",
    "        # Update cell state\n",
    "        c_t = f_t * c_prev.t() + i_t * g_t\n",
    "\n",
    "        # Update hidden state\n",
    "        h_t = o_t * torch.tanh(c_t)\n",
    "\n",
    "        return h_t.t(), c_t.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4468ad4e-deff-46a0-ab5c-4deda7ebb155",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \"\"\"Multi-layer LSTM implemented from scratch\"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # Create LSTM layers\n",
    "        self.lstm_cells = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            layer_input_size = input_size if i == 0 else hidden_size\n",
    "            self.lstm_cells.append(LSTMCell(layer_input_size, hidden_size))\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Output layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(batch_size, x.device)\n",
    "\n",
    "        # Process each time step\n",
    "        outputs = []\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :]\n",
    "\n",
    "            # Process through each LSTM layer\n",
    "            layer_input = x_t\n",
    "            new_hidden = []\n",
    "            for i, lstm_cell in enumerate(self.lstm_cells):\n",
    "                h_t, c_t = lstm_cell(layer_input, (hidden[i][0], hidden[i][1]))\n",
    "                new_hidden.append((h_t, c_t))\n",
    "                layer_input = self.dropout(h_t)\n",
    "\n",
    "            hidden = new_hidden\n",
    "            outputs.append(layer_input)\n",
    "\n",
    "        # Use the last output for prediction\n",
    "        last_output = outputs[-1]\n",
    "        prediction = self.fc(last_output)\n",
    "\n",
    "        return prediction, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size, device):\n",
    "        \"\"\"Initialize hidden states\"\"\"\n",
    "        hidden = []\n",
    "        for _ in range(self.num_layers):\n",
    "            h = torch.zeros(batch_size, self.hidden_size, device=device)\n",
    "            c = torch.zeros(batch_size, self.hidden_size, device=device)\n",
    "            hidden.append((h, c))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a43341f-1b40-4027-a702-8ead8229f31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticAlgorithmOptimizer:\n",
    "    \"\"\"Genetic Algorithm for LSTM hyperparameter optimization\"\"\"\n",
    "    def __init__(self, population_size: int = 15, generations: int = 8,\n",
    "                 mutation_rate: float = 0.15, crossover_rate: float = 0.8):\n",
    "        self.population_size = population_size\n",
    "        self.generations = generations\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "\n",
    "        # Define hyperparameter ranges optimized for stock prediction\n",
    "        self.param_ranges = {\n",
    "            'sequence_length': (20, 90),  # Days to look back\n",
    "            'hidden_size': (50, 200),     # LSTM hidden units\n",
    "            'num_layers': (2, 4),         # Number of LSTM layers\n",
    "            'dropout': (0.1, 0.4),        # Dropout rate\n",
    "            'learning_rate': (0.0005, 0.01),  # Learning rate\n",
    "            'batch_size': [16, 32, 64],   # Batch sizes (powers of 2)\n",
    "            'epochs': (50, 150)           # Training epochs\n",
    "        }\n",
    "        self.best_individuals = []  # Track best individuals from each generation\n",
    "\n",
    "    def create_individual(self) -> GAHyperparams:\n",
    "        \"\"\"Create a random individual (hyperparameter set)\"\"\"\n",
    "        return GAHyperparams(\n",
    "            sequence_length=random.randint(*self.param_ranges['sequence_length']),\n",
    "            hidden_size=random.randint(*self.param_ranges['hidden_size']),\n",
    "            num_layers=random.randint(*self.param_ranges['num_layers']),\n",
    "            dropout=random.uniform(*self.param_ranges['dropout']),\n",
    "            learning_rate=random.uniform(*self.param_ranges['learning_rate']),\n",
    "            batch_size=random.choice(self.param_ranges['batch_size']),\n",
    "            epochs=random.randint(*self.param_ranges['epochs'])\n",
    "        )\n",
    "\n",
    "    def initialize_population(self) -> List[GAHyperparams]:\n",
    "        \"\"\"Initialize the population\"\"\"\n",
    "        population = []\n",
    "\n",
    "        # Add some good starting points based on common practices\n",
    "        good_configs = [\n",
    "            GAHyperparams(60, 100, 3, 0.2, 0.001, 32, 100),  # Your original config\n",
    "            GAHyperparams(30, 128, 2, 0.25, 0.002, 64, 80),  # Fast training\n",
    "            GAHyperparams(90, 64, 4, 0.3, 0.0008, 16, 120),  # Deep model\n",
    "        ]\n",
    "\n",
    "        # Add good configs to population\n",
    "        for config in good_configs[:min(len(good_configs), self.population_size)]:\n",
    "            population.append(config)\n",
    "\n",
    "        # Fill rest with random individuals\n",
    "        while len(population) < self.population_size:\n",
    "            population.append(self.create_individual())\n",
    "\n",
    "        return population\n",
    "\n",
    "    def fitness_function(self, individual: GAHyperparams, predictor) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate fitness of an individual (hyperparameter set)\n",
    "        Lower fitness is better (we're minimizing validation loss)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(f\"Testing: seq_len={individual.sequence_length}, hidden={individual.hidden_size}, \"\n",
    "                  f\"layers={individual.num_layers}, lr={individual.learning_rate:.4f}\")\n",
    "\n",
    "            # Prepare data with individual's sequence length\n",
    "            original_seq_len = predictor.sequence_length\n",
    "            predictor.sequence_length = individual.sequence_length\n",
    "\n",
    "            # Get fresh data preparation\n",
    "            X_train, y_train, X_val, y_val, _ = predictor.prepare_data(\n",
    "                predictor.raw_data, predictor.feature_cols\n",
    "            )\n",
    "\n",
    "            # Create model with individual's hyperparameters\n",
    "            model = LSTM(\n",
    "                input_size=X_train.shape[2],\n",
    "                hidden_size=individual.hidden_size,\n",
    "                num_layers=individual.num_layers,\n",
    "                output_size=1,\n",
    "                dropout=individual.dropout\n",
    "            ).to(predictor.device)\n",
    "\n",
    "            # Train with limited epochs for GA speed\n",
    "            train_epochs = min(individual.epochs, 60)  # Cap epochs for GA speed\n",
    "            val_loss = self._train_and_evaluate(\n",
    "                model, individual, X_train, y_train, X_val, y_val, train_epochs\n",
    "            )\n",
    "\n",
    "            # Restore original sequence length\n",
    "            predictor.sequence_length = original_seq_len\n",
    "\n",
    "            print(f\"→ Validation Loss: {val_loss:.6f}\")\n",
    "            return val_loss\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"→ Error: {str(e)}\")\n",
    "            return float('inf')\n",
    "\n",
    "    def _train_and_evaluate(self, model, params, X_train, y_train, X_val, y_val, epochs):\n",
    "        \"\"\"Train model and return validation loss\"\"\"\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params.learning_rate)\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        patience = 10\n",
    "        patience_counter = 0\n",
    "\n",
    "        # Create data loader for batching\n",
    "        train_size = X_train.shape[0]\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            num_batches = 0\n",
    "\n",
    "            # Mini-batch training\n",
    "            for i in range(0, train_size, params.batch_size):\n",
    "                end_idx = min(i + params.batch_size, train_size)\n",
    "                batch_X = X_train[i:end_idx]\n",
    "                batch_y = y_train[i:end_idx]\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs, _ = model(batch_X)\n",
    "                loss = criterion(outputs.squeeze(), batch_y)\n",
    "                loss.backward()\n",
    "\n",
    "                # Gradient clipping for stability\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "\n",
    "            # Validation\n",
    "            if epoch % 5 == 0:  # Check validation every 5 epochs\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_outputs, _ = model(X_val)\n",
    "                    val_loss = criterion(val_outputs.squeeze(), y_val).item()\n",
    "\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "\n",
    "                # Early stopping for GA efficiency\n",
    "                if patience_counter >= patience:\n",
    "                    break\n",
    "\n",
    "        return best_val_loss\n",
    "\n",
    "    def selection(self, population: List[GAHyperparams],\n",
    "                  fitness_scores: List[float]) -> List[GAHyperparams]:\n",
    "        \"\"\"Tournament selection\"\"\"\n",
    "        selected = []\n",
    "        tournament_size = 3\n",
    "\n",
    "        for _ in range(len(population)):\n",
    "            # Select random individuals for tournament\n",
    "            tournament_indices = random.sample(range(len(population)),\n",
    "                                             min(tournament_size, len(population)))\n",
    "            tournament_fitness = [fitness_scores[i] for i in tournament_indices]\n",
    "\n",
    "            # Select best individual from tournament (lowest fitness)\n",
    "            winner_idx = tournament_indices[tournament_fitness.index(min(tournament_fitness))]\n",
    "            selected.append(population[winner_idx])\n",
    "\n",
    "        return selected\n",
    "\n",
    "    def crossover(self, parent1: GAHyperparams,\n",
    "                  parent2: GAHyperparams) -> Tuple[GAHyperparams, GAHyperparams]:\n",
    "        \"\"\"Uniform crossover\"\"\"\n",
    "        if random.random() > self.crossover_rate:\n",
    "            return parent1, parent2\n",
    "\n",
    "        # Create offspring by mixing parameters\n",
    "        child1 = GAHyperparams(\n",
    "            sequence_length=parent1.sequence_length if random.random() < 0.5 else parent2.sequence_length,\n",
    "            hidden_size=parent1.hidden_size if random.random() < 0.5 else parent2.hidden_size,\n",
    "            num_layers=parent1.num_layers if random.random() < 0.5 else parent2.num_layers,\n",
    "            dropout=parent1.dropout if random.random() < 0.5 else parent2.dropout,\n",
    "            learning_rate=parent1.learning_rate if random.random() < 0.5 else parent2.learning_rate,\n",
    "            batch_size=parent1.batch_size if random.random() < 0.5 else parent2.batch_size,\n",
    "            epochs=parent1.epochs if random.random() < 0.5 else parent2.epochs\n",
    "        )\n",
    "\n",
    "        child2 = GAHyperparams(\n",
    "            sequence_length=parent2.sequence_length if random.random() < 0.5 else parent1.sequence_length,\n",
    "            hidden_size=parent2.hidden_size if random.random() < 0.5 else parent1.hidden_size,\n",
    "            num_layers=parent2.num_layers if random.random() < 0.5 else parent1.num_layers,\n",
    "            dropout=parent2.dropout if random.random() < 0.5 else parent1.dropout,\n",
    "            learning_rate=parent2.learning_rate if random.random() < 0.5 else parent1.learning_rate,\n",
    "            batch_size=parent2.batch_size if random.random() < 0.5 else parent1.batch_size,\n",
    "            epochs=parent2.epochs if random.random() < 0.5 else parent1.epochs\n",
    "        )\n",
    "\n",
    "        return child1, child2\n",
    "\n",
    "    def mutate(self, individual: GAHyperparams) -> GAHyperparams:\n",
    "        \"\"\"Mutate an individual\"\"\"\n",
    "        if random.random() > self.mutation_rate:\n",
    "            return individual\n",
    "\n",
    "        # Choose random parameter to mutate\n",
    "        param_to_mutate = random.choice(list(self.param_ranges.keys()))\n",
    "\n",
    "        if param_to_mutate == 'sequence_length':\n",
    "            individual.sequence_length = random.randint(*self.param_ranges['sequence_length'])\n",
    "        elif param_to_mutate == 'hidden_size':\n",
    "            individual.hidden_size = random.randint(*self.param_ranges['hidden_size'])\n",
    "        elif param_to_mutate == 'num_layers':\n",
    "            individual.num_layers = random.randint(*self.param_ranges['num_layers'])\n",
    "        elif param_to_mutate == 'dropout':\n",
    "            individual.dropout = random.uniform(*self.param_ranges['dropout'])\n",
    "        elif param_to_mutate == 'learning_rate':\n",
    "            individual.learning_rate = random.uniform(*self.param_ranges['learning_rate'])\n",
    "        elif param_to_mutate == 'batch_size':\n",
    "            individual.batch_size = random.choice(self.param_ranges['batch_size'])\n",
    "        elif param_to_mutate == 'epochs':\n",
    "            individual.epochs = random.randint(*self.param_ranges['epochs'])\n",
    "\n",
    "        return individual\n",
    "\n",
    "    def optimize(self, predictor) -> Tuple[GAHyperparams, float]:\n",
    "        \"\"\"Main GA optimization loop\"\"\"\n",
    "        print(f\"\\nStarting Genetic Algorithm Optimization\")\n",
    "        print(f\"Population: {self.population_size}, Generations: {self.generations}\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        # Initialize population\n",
    "        population = self.initialize_population()\n",
    "        best_individual = None\n",
    "        best_fitness = float('inf')\n",
    "\n",
    "        for generation in range(self.generations):\n",
    "            print(f\"\\nGeneration {generation + 1}/{self.generations}\")\n",
    "            print(\"-\" * 40)\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Evaluate fitness\n",
    "            fitness_scores = []\n",
    "            for i, individual in enumerate(population):\n",
    "                print(f\"Individual {i+1}/{len(population)}\")\n",
    "                fitness = self.fitness_function(individual, predictor)\n",
    "                fitness_scores.append(fitness)\n",
    "\n",
    "                # Track best individual\n",
    "                if fitness < best_fitness:\n",
    "                    best_fitness = fitness\n",
    "                    best_individual = individual\n",
    "\n",
    "            generation_time = time.time() - start_time\n",
    "            avg_fitness = np.mean(fitness_scores)\n",
    "\n",
    "            print(f\"\\nGeneration {generation + 1} Results:\")\n",
    "            print(f\"Best Fitness: {min(fitness_scores):.6f}\")\n",
    "            print(f\"Average Fitness: {avg_fitness:.6f}\")\n",
    "            print(f\"Time: {generation_time:.1f}s\")\n",
    "\n",
    "            # Store best individual from this generation\n",
    "            gen_best_idx = fitness_scores.index(min(fitness_scores))\n",
    "            self.best_individuals.append((population[gen_best_idx], min(fitness_scores)))\n",
    "\n",
    "            # Early stopping if we're not improving\n",
    "            if generation >= 3:\n",
    "                recent_improvements = [self.best_individuals[i][1] for i in range(-3, 0)]\n",
    "                if max(recent_improvements) - min(recent_improvements) < 0.0001:\n",
    "                    print(f\"\\nEarly stopping: No significant improvement in last 3 generations\")\n",
    "                    break\n",
    "\n",
    "            # Selection\n",
    "            selected = self.selection(population, fitness_scores)\n",
    "\n",
    "            # Create new population through crossover and mutation\n",
    "            new_population = []\n",
    "            for i in range(0, len(selected), 2):\n",
    "                parent1 = selected[i]\n",
    "                parent2 = selected[i + 1] if i + 1 < len(selected) else selected[0]\n",
    "\n",
    "                child1, child2 = self.crossover(parent1, parent2)\n",
    "                child1 = self.mutate(child1)\n",
    "                child2 = self.mutate(child2)\n",
    "\n",
    "                new_population.extend([child1, child2])\n",
    "\n",
    "            population = new_population[:self.population_size]\n",
    "\n",
    "        print(f\"\\nGA Optimization Complete!\")\n",
    "        print(f\"Best Fitness Achieved: {best_fitness:.6f}\")\n",
    "        return best_individual, best_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "573b2e6d-eb18-4362-a753-10d16212a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockPredictor:\n",
    "    \"\"\"Stock price predictor using LSTM\"\"\"\n",
    "    def __init__(self, symbol='AAPL', sequence_length=60, hidden_size=50, num_layers=2):\n",
    "        self.symbol = symbol\n",
    "        self.sequence_length = sequence_length\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.raw_data = None\n",
    "        self.feature_cols = ['Close', 'Volume', 'High', 'Low', 'Open']\n",
    "\n",
    "    def fetch_data(self, period='2y'):\n",
    "        \"\"\"Fetch stock data from Yahoo Finance\"\"\"\n",
    "        print(f\"Fetching data for {self.symbol}...\")\n",
    "        stock = yf.Ticker(self.symbol)\n",
    "        data = stock.history(period=period)\n",
    "        self.raw_data = data\n",
    "        return data\n",
    "\n",
    "    def prepare_data(self, data, feature_cols=['Close']):\n",
    "        \"\"\"Prepare data for training\"\"\"\n",
    "        df = data[feature_cols].copy()\n",
    "\n",
    "        # Handle NaN values\n",
    "        if df.isna().sum().sum() > 0:\n",
    "            print(\"NaNs detected! Applying forward fill...\")\n",
    "            df = df.ffill().bfill()\n",
    "\n",
    "        scaled_data = self.scaler.fit_transform(df)\n",
    "\n",
    "        X, y = [], []\n",
    "        for i in range(self.sequence_length, len(scaled_data)):\n",
    "            X.append(scaled_data[i-self.sequence_length:i])\n",
    "            y.append(scaled_data[i, 0])  # Predict 'Close' price\n",
    "\n",
    "        X, y = np.array(X), np.array(y)\n",
    "\n",
    "        # Split into training and test sets\n",
    "        train_size = int(len(X) * 0.8)\n",
    "        X_train, X_test = X[:train_size], X[train_size:]\n",
    "        y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "        # Convert to PyTorch tensors\n",
    "        X_train = torch.FloatTensor(X_train).to(self.device)\n",
    "        y_train = torch.FloatTensor(y_train).to(self.device)\n",
    "        X_test = torch.FloatTensor(X_test).to(self.device)\n",
    "        y_test = torch.FloatTensor(y_test).to(self.device)\n",
    "\n",
    "        return X_train, y_train, X_test, y_test, df.index[self.sequence_length:]\n",
    "\n",
    "    def train_model(self, X_train, y_train, X_test, y_test, epochs=100, learning_rate=0.001):\n",
    "        \"\"\"Train the LSTM model\"\"\"\n",
    "        input_size = X_train.shape[2]\n",
    "\n",
    "        self.model = LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.num_layers,\n",
    "            output_size=1\n",
    "        ).to(self.device)\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "\n",
    "        train_losses, test_losses = [], []\n",
    "        print(\"Training model...\")\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Training\n",
    "            self.model.train()\n",
    "            optimizer.zero_grad()\n",
    "            train_pred, _ = self.model(X_train)\n",
    "            train_loss = criterion(train_pred.squeeze(), y_train)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Validation\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                test_pred, _ = self.model(X_test)\n",
    "                test_loss = criterion(test_pred.squeeze(), y_test)\n",
    "\n",
    "            train_losses.append(train_loss.item())\n",
    "            test_losses.append(test_loss.item())\n",
    "\n",
    "            if (epoch + 1) % 20 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss.item():.6f}, Test Loss: {test_loss.item():.6f}\")\n",
    "\n",
    "        return train_losses, test_losses\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Make predictions\"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions, _ = self.model(X_test)\n",
    "        return predictions.cpu().detach().numpy()\n",
    "\n",
    "    def inverse_transform(self, scaled_data):\n",
    "        \"\"\"Inverse transform scaled predictions back to original scale\"\"\"\n",
    "        dummy = np.zeros((len(scaled_data), self.scaler.n_features_in_))\n",
    "        dummy[:, 0] = scaled_data.flatten()\n",
    "        return self.scaler.inverse_transform(dummy)[:, 0]\n",
    "\n",
    "    def evaluate_model(self, y_true, y_pred):\n",
    "        \"\"\"Evaluate model performance\"\"\"\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "        return {'MSE': mse, 'MAE': mae, 'RMSE': rmse, 'MAPE': mape}\n",
    "\n",
    "    def plot_results(self, y_true, y_pred, dates, train_losses, test_losses):\n",
    "        \"\"\"Plot actual vs predicted prices and training history\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "        # Plot 1: Actual vs Predicted\n",
    "        ax1.plot(dates, y_true, label='Actual', linewidth=2)\n",
    "        ax1.plot(dates, y_pred, label='Predicted', linewidth=2, linestyle='--')\n",
    "        ax1.set_title(f'{self.symbol} Stock Price Prediction', fontsize=14, fontweight='bold')\n",
    "        ax1.set_xlabel('Date')\n",
    "        ax1.set_ylabel('Price ($)')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "\n",
    "        # Plot 2: Training and Validation Loss\n",
    "        ax2.plot(train_losses, label='Training Loss', linewidth=2)\n",
    "        ax2.plot(test_losses, label='Validation Loss', linewidth=2)\n",
    "        ax2.set_title('Training History')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "101fed02-6bd2-4a10-b980-02d6366f3503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_selection():\n",
    "    \"\"\"Interactive company selection\"\"\"\n",
    "    popular_stocks = {\n",
    "        '1': ('AAPL', 'Apple Inc.'),\n",
    "        '2': ('GOOGL', 'Alphabet Inc. (Google)'),\n",
    "        '3': ('MSFT', 'Microsoft Corporation'),\n",
    "        '4': ('AMZN', 'Amazon.com Inc.'),\n",
    "        '5': ('TSLA', 'Tesla Inc.'),\n",
    "        '6': ('META', 'Meta Platforms Inc. (Facebook)'),\n",
    "        '7': ('NVDA', 'NVIDIA Corporation'),\n",
    "        '8': ('NFLX', 'Netflix Inc.'),\n",
    "        '9': ('JPM', 'JPMorgan Chase & Co.'),\n",
    "        '10': ('JNJ', 'Johnson & Johnson'),\n",
    "    }\n",
    "\n",
    "    print(\"\\n\" + \"=\"*45)\n",
    "    print(\"GA-OPTIMIZED STOCK PRICE PREDICTION SYSTEM\")\n",
    "    print(\"=\"*45)\n",
    "    print(\"\\nSelect a company to predict:\")\n",
    "    print(\"-\" * 40)\n",
    "    for key, (symbol, name) in popular_stocks.items():\n",
    "        print(f\"{key:2}. {symbol:5} - {name}\")\n",
    "    print(f\"{len(popular_stocks)+1:2}. Custom - Enter your own stock symbol\")\n",
    "\n",
    "    while True:\n",
    "        choice = input(f\"\\nEnter your choice (1-{len(popular_stocks)+1}): \").strip()\n",
    "        if choice in popular_stocks:\n",
    "            symbol, name = popular_stocks[choice]\n",
    "            print(f\"\\nSelected: {name} ({symbol})\")\n",
    "            return symbol, name\n",
    "        elif choice == str(len(popular_stocks)+1):\n",
    "            while True:\n",
    "                symbol = input(\"Enter stock symbol (e.g., AAPL, GOOGL): \").strip().upper()\n",
    "                if symbol and len(symbol) <= 6:\n",
    "                    print(f\"\\n Selected: {symbol}\")\n",
    "                    return symbol, symbol\n",
    "                print(\"Please enter a valid stock symbol\")\n",
    "        else:\n",
    "            print(f\"Please enter a number between 1 and {len(popular_stocks)+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "637c0e34-54ad-4124-abcb-0fa2446d95aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_day_price(predictor, X_test, current_price):\n",
    "    \"\"\"Enhanced next day prediction with confidence indicators\"\"\"\n",
    "    last_sequence = X_test[-1:].to(predictor.device)\n",
    "    with torch.no_grad():\n",
    "        future_pred, _ = predictor.model(last_sequence)\n",
    "\n",
    "    predicted_price = predictor.inverse_transform(future_pred.cpu().detach().numpy())[0]\n",
    "    price_change = predicted_price - current_price\n",
    "    price_change_pct = (price_change / current_price) * 100\n",
    "\n",
    "    if price_change > 0:\n",
    "        trend = \"📈 BULLISH\"\n",
    "    else:\n",
    "        trend = \"📉 BEARISH\"\n",
    "\n",
    "    return predicted_price, price_change, price_change_pct, trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8ba5a967-64aa-4453-8fe4-5e98aa897d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_ga_results(best_params, best_fitness):\n",
    "    \"\"\"Display GA optimization results\"\"\"\n",
    "    print(f\"\\nGENETIC ALGORITHM OPTIMIZATION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Best Hyperparameters Found:\")\n",
    "    print(f\"Sequence Length: {best_params.sequence_length} days\")\n",
    "    print(f\"Hidden Size: {best_params.hidden_size} units\")\n",
    "    print(f\"Number of Layers: {best_params.num_layers}\")\n",
    "    print(f\"Dropout Rate: {best_params.dropout:.3f}\")\n",
    "    print(f\"Learning Rate: {best_params.learning_rate:.6f}\")\n",
    "    print(f\"Batch Size: {best_params.batch_size}\")\n",
    "    print(f\"Epochs: {best_params.epochs}\")\n",
    "    print(f\"Best Validation Loss: {best_fitness:.6f}\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "281957e8-e52f-45b1-b285-d864ba343449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_prediction_summary(symbol, company_name, current_price, predicted_price,\n",
    "                             price_change, price_change_pct, trend, metrics, ga_optimized=False):\n",
    "    \"\"\"Display comprehensive prediction summary\"\"\"\n",
    "    optimization_text = \"GA-OPTIMIZED \" if ga_optimized else \"\"\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"{optimization_text}STOCK PREDICTION RESULTS\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"\\nCOMPANY: {company_name} ({symbol})\")\n",
    "    print(f\"CURRENT PRICE: ${current_price:.2f}\")\n",
    "    print(f\"PREDICTED NEXT DAY PRICE: ${predicted_price:.2f}\")\n",
    "    print(f\"EXPECTED CHANGE: ${price_change:+.2f} ({price_change_pct:+.2f}%)\")\n",
    "    print(f\"TREND SIGNAL: {trend}\")\n",
    "\n",
    "    print(f\"\\nMODEL ACCURACY METRICS:\")\n",
    "    print(f\"Mean Absolute Percentage Error: {metrics['MAPE']:.2f}%\")\n",
    "    print(f\"Average Error: ${metrics['MAE']:.2f}\")\n",
    "    print(f\"Root Mean Square Error: ${metrics['RMSE']:.2f}\")\n",
    "\n",
    "    # Confidence indicator based on MAPE\n",
    "    if metrics['MAPE'] < 3.0:\n",
    "        confidence = \"HIGH\"\n",
    "    elif metrics['MAPE'] < 5.0:\n",
    "        confidence = \"MEDIUM\"\n",
    "    else:\n",
    "        confidence = \"LOW\"\n",
    "\n",
    "    print(f\"Prediction Confidence: {confidence}\")\n",
    "\n",
    "    if ga_optimized:\n",
    "        print(f\"\\n Hyperparameters optimized using Genetic Algorithm\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DISCLAIMER: This prediction is for educational purposes only.\")\n",
    "    print(\"Always consult financial advisors before making investment decisions.\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "628b6a3e-0c02-48c3-94ca-e7544a3ac23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_with_ga():\n",
    "    \"\"\"Main function with GA optimization\"\"\"\n",
    "    # Get user's company choice\n",
    "    symbol, company_name = get_company_selection()\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"GA-OPTIMIZED STOCK PREDICTION FOR {company_name} ({symbol})\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Ask user if they want to use GA optimization\n",
    "    print(\"\\n Optimization Options:\")\n",
    "    print(\"1. Use Genetic Algorithm to find best hyperparameters (Recommended, ~10-15 minutes)\")\n",
    "    print(\"2. Use default hyperparameters (Fast, ~1 minute)\")\n",
    "\n",
    "    while True:\n",
    "        choice = input(\"\\nChoose optimization method (1 or 2): \").strip()\n",
    "        if choice in ['1', '2']:\n",
    "            break\n",
    "        print(\"Please enter 1 or 2\")\n",
    "\n",
    "    use_ga = (choice == '1')\n",
    "\n",
    "    # Initialize predictor with default parameters\n",
    "    predictor = StockPredictor(\n",
    "        symbol=symbol,\n",
    "        sequence_length=60,\n",
    "        hidden_size=100,\n",
    "        num_layers=3\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Fetch and prepare data\n",
    "        print(f\"\\nFetching data for {company_name}...\")\n",
    "        data = predictor.fetch_data(period='2y')\n",
    "        print(f\"Last data date: {data.index[-1].date()}\")\n",
    "        print(f\"Predicting price for: {data.index[-1].date() + timedelta(days=1)}\")\n",
    "\n",
    "        current_price = data['Close'].iloc[-1]\n",
    "        feature_cols = ['Close', 'Volume', 'High', 'Low', 'Open']\n",
    "        predictor.feature_cols = feature_cols\n",
    "\n",
    "        best_params = None\n",
    "        if use_ga:\n",
    "            # Initialize GA optimizer\n",
    "            ga_optimizer = GeneticAlgorithmOptimizer(\n",
    "                population_size=12,  # Smaller for faster execution\n",
    "                generations=6,       # Fewer generations for demo\n",
    "                mutation_rate=0.15,\n",
    "                crossover_rate=0.8\n",
    "            )\n",
    "\n",
    "            # Run GA optimization\n",
    "            best_params, best_fitness = ga_optimizer.optimize(predictor)\n",
    "            display_ga_results(best_params, best_fitness)\n",
    "\n",
    "            # Update predictor with optimized parameters\n",
    "            predictor.sequence_length = best_params.sequence_length\n",
    "            predictor.hidden_size = best_params.hidden_size\n",
    "            predictor.num_layers = best_params.num_layers\n",
    "\n",
    "        # Prepare data with final parameters\n",
    "        print(f\"\\nPreparing data with {len(feature_cols)} features...\")\n",
    "        X_train, y_train, X_test, y_test, dates = predictor.prepare_data(data, feature_cols)\n",
    "        print(f\"Training data shape: {X_train.shape}\")\n",
    "        print(f\"Test data shape: {X_test.shape}\")\n",
    "\n",
    "        # Train final model\n",
    "        print(f\"\\nTraining final model for {company_name}...\")\n",
    "        if best_params and use_ga:\n",
    "            train_losses, test_losses = predictor.train_model(\n",
    "                X_train, y_train, X_test, y_test,\n",
    "                epochs=best_params.epochs,\n",
    "                learning_rate=best_params.learning_rate\n",
    "            )\n",
    "        else:\n",
    "            train_losses, test_losses = predictor.train_model(\n",
    "                X_train, y_train, X_test, y_test,\n",
    "                epochs=100,\n",
    "                learning_rate=0.001\n",
    "            )\n",
    "\n",
    "        # Make predictions on test data\n",
    "        print(\"Making test predictions...\")\n",
    "        predictions = predictor.predict(X_test)\n",
    "\n",
    "        # Inverse transform to get actual prices\n",
    "        y_test_actual = predictor.inverse_transform(y_test.cpu().numpy())\n",
    "        y_pred_actual = predictor.inverse_transform(predictions)\n",
    "\n",
    "        # Evaluate model\n",
    "        metrics = predictor.evaluate_model(y_test_actual, y_pred_actual)\n",
    "\n",
    "        # Predict next day price\n",
    "        predicted_price, price_change, price_change_pct, trend = predict_next_day_price(\n",
    "            predictor, X_test, current_price\n",
    "        )\n",
    "\n",
    "        # Display results\n",
    "        display_prediction_summary(\n",
    "            symbol, company_name, current_price, predicted_price,\n",
    "            price_change, price_change_pct, trend, metrics, ga_optimized=use_ga\n",
    "        )\n",
    "\n",
    "        print(f\"\\nPrediction completed for {company_name}!\")\n",
    "        if use_ga and best_params:\n",
    "            print(f\"\\nFinal Optimized Configuration:\")\n",
    "            for param, value in best_params.to_dict().items():\n",
    "                print(f\"{param}: {value}\")\n",
    "\n",
    "        # Return results including predictions\n",
    "        return predicted_price, metrics, best_params\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {symbol}: {str(e)}\")\n",
    "        print(\"Try selecting a different stock symbol or check your internet connection.\")\n",
    "        return None, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8e784f84-adb5-4465-a3ca-38f3f0ea10e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_ga_predict(symbol, use_ga=True):\n",
    "    \"\"\"Quick GA-optimized prediction function for specific stocks\"\"\"\n",
    "    print(f\"\\nQuick GA Prediction for {symbol}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    predictor = StockPredictor(\n",
    "        symbol=symbol,\n",
    "        sequence_length=60,\n",
    "        hidden_size=100,\n",
    "        num_layers=3\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        data = predictor.fetch_data(period='2y')\n",
    "        feature_cols = ['Close', 'Volume', 'High', 'Low', 'Open']\n",
    "        predictor.feature_cols = feature_cols\n",
    "\n",
    "        best_params = None\n",
    "        if use_ga:\n",
    "            # Quick GA optimization with smaller parameters\n",
    "            ga_optimizer = GeneticAlgorithmOptimizer(\n",
    "                population_size=8,\n",
    "                generations=4,\n",
    "                mutation_rate=0.2,\n",
    "                crossover_rate=0.8\n",
    "            )\n",
    "            best_params, _ = ga_optimizer.optimize(predictor)\n",
    "\n",
    "            # Update predictor\n",
    "            predictor.sequence_length = best_params.sequence_length\n",
    "            predictor.hidden_size = best_params.hidden_size\n",
    "            predictor.num_layers = best_params.num_layers\n",
    "\n",
    "        X_train, y_train, X_test, y_test, _ = predictor.prepare_data(data, feature_cols)\n",
    "\n",
    "        # Train with optimized or default parameters\n",
    "        if best_params:\n",
    "            predictor.train_model(X_train, y_train, X_test, y_test,\n",
    "                                epochs=min(best_params.epochs, 80),\n",
    "                                learning_rate=best_params.learning_rate)\n",
    "        else:\n",
    "            predictor.train_model(X_train, y_train, X_test, y_test, epochs=80, learning_rate=0.001)\n",
    "\n",
    "        predictions = predictor.predict(X_test)\n",
    "        y_test_actual = predictor.inverse_transform(y_test.cpu().numpy())\n",
    "        y_pred_actual = predictor.inverse_transform(predictions)\n",
    "        metrics = predictor.evaluate_model(y_test_actual, y_pred_actual)\n",
    "\n",
    "        current_price = data['Close'].iloc[-1]\n",
    "        predicted_price, price_change, price_change_pct, trend = predict_next_day_price(\n",
    "            predictor, X_test, current_price\n",
    "        )\n",
    "\n",
    "        optimization_text = \"GA-Optimized \" if use_ga else \"Default\"\n",
    "        print(f\"\\n{symbol} {optimization_text}PREDICTION:\")\n",
    "        print(f\"Current: ${current_price:.2f} → Predicted: ${predicted_price:.2f}\")\n",
    "        print(f\"Change: ${price_change:+.2f} ({price_change_pct:+.2f}%) - {trend}\")\n",
    "        print(f\"Model Accuracy: {metrics['MAPE']:.2f}% MAPE\")\n",
    "        if best_params:\n",
    "            print(f\"Best Config: seq_len={best_params.sequence_length}, hidden={best_params.hidden_size}, layers={best_params.num_layers}\")\n",
    "\n",
    "        return predicted_price, metrics, best_params\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "25476105-0fc3-4081-981e-d9a56ea89828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_optimization_methods(symbol):\n",
    "    \"\"\"Compare GA-optimized vs default hyperparameters\"\"\"\n",
    "    print(f\"\\nCOMPARING OPTIMIZATION METHODS FOR {symbol}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Test with default parameters\n",
    "    print(\"\\nTesting with DEFAULT hyperparameters...\")\n",
    "    default_pred, default_metrics, _ = quick_ga_predict(symbol, use_ga=False)\n",
    "\n",
    "    # Test with GA optimization\n",
    "    print(\"\\nTesting with GA-OPTIMIZED hyperparameters...\")\n",
    "    ga_pred, ga_metrics, ga_params = quick_ga_predict(symbol, use_ga=True)\n",
    "\n",
    "    if default_pred and ga_pred:\n",
    "        print(f\"\\nCOMPARISON RESULTS:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Method          MAPE    RMSE     MAE\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Default      {default_metrics['MAPE']:7.2f}% {default_metrics['RMSE']:7.2f} {default_metrics['MAE']:7.2f}\")\n",
    "        print(f\"GA-Optimized {ga_metrics['MAPE']:7.2f}% {ga_metrics['RMSE']:7.2f} {ga_metrics['MAE']:7.2f}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        improvement = default_metrics['MAPE'] - ga_metrics['MAPE']\n",
    "        if improvement > 0:\n",
    "            print(f\"GA Optimization improved MAPE by {improvement:.2f}%\")\n",
    "        else:\n",
    "            print(f\"Default parameters performed better by {abs(improvement):.2f}%\")\n",
    "\n",
    "    return ga_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ef1c5a63-e2bb-4494-b1e6-a645de95e8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to GA-Optimized LSTM Stock Prediction!\n",
      "This system uses Genetic Algorithms to find optimal hyperparameters\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Choose mode:\n",
      "1. Interactive prediction with GA\n",
      "2. Quick comparison test\n",
      "Enter choise (1 or 2):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================\n",
      "GA-OPTIMIZED STOCK PRICE PREDICTION SYSTEM\n",
      "=============================================\n",
      "\n",
      "Select a company to predict:\n",
      "----------------------------------------\n",
      "1 . AAPL  - Apple Inc.\n",
      "2 . GOOGL - Alphabet Inc. (Google)\n",
      "3 . MSFT  - Microsoft Corporation\n",
      "4 . AMZN  - Amazon.com Inc.\n",
      "5 . TSLA  - Tesla Inc.\n",
      "6 . META  - Meta Platforms Inc. (Facebook)\n",
      "7 . NVDA  - NVIDIA Corporation\n",
      "8 . NFLX  - Netflix Inc.\n",
      "9 . JPM   - JPMorgan Chase & Co.\n",
      "10. JNJ   - Johnson & Johnson\n",
      "11. Custom - Enter your own stock symbol\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your choice (1-11):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected: Amazon.com Inc. (AMZN)\n",
      "\n",
      "============================================================\n",
      "GA-OPTIMIZED STOCK PREDICTION FOR Amazon.com Inc. (AMZN)\n",
      "============================================================\n",
      "\n",
      " Optimization Options:\n",
      "1. Use Genetic Algorithm to find best hyperparameters (Recommended, ~10-15 minutes)\n",
      "2. Use default hyperparameters (Fast, ~1 minute)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Choose optimization method (1 or 2):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching data for Amazon.com Inc....\n",
      "Fetching data for AMZN...\n",
      "Last data date: 2025-10-29\n",
      "Predicting price for: 2025-10-30\n",
      "\n",
      "Preparing data with 5 features...\n",
      "Training data shape: torch.Size([353, 60, 5])\n",
      "Test data shape: torch.Size([89, 60, 5])\n",
      "\n",
      "Training final model for Amazon.com Inc....\n",
      "Training model...\n",
      "Epoch [20/100], Train Loss: 0.034116, Test Loss: 0.103115\n",
      "Epoch [40/100], Train Loss: 0.013910, Test Loss: 0.021504\n",
      "Epoch [60/100], Train Loss: 0.007035, Test Loss: 0.007388\n",
      "Epoch [80/100], Train Loss: 0.007130, Test Loss: 0.004254\n",
      "Epoch [100/100], Train Loss: 0.006049, Test Loss: 0.003973\n",
      "Making test predictions...\n",
      "\n",
      "========================================\n",
      "STOCK PREDICTION RESULTS\n",
      "========================================\n",
      "\n",
      "COMPANY: Amazon.com Inc. (AMZN)\n",
      "CURRENT PRICE: $230.30\n",
      "PREDICTED NEXT DAY PRICE: $217.22\n",
      "EXPECTED CHANGE: $-13.08 (-5.68%)\n",
      "TREND SIGNAL: 📉 BEARISH\n",
      "\n",
      "MODEL ACCURACY METRICS:\n",
      "Mean Absolute Percentage Error: 2.55%\n",
      "Average Error: $5.73\n",
      "Root Mean Square Error: $6.89\n",
      "Prediction Confidence: HIGH\n",
      "\n",
      "================================================================================\n",
      "DISCLAIMER: This prediction is for educational purposes only.\n",
      "Always consult financial advisors before making investment decisions.\n",
      "================================================================================\n",
      "\n",
      "Prediction completed for Amazon.com Inc.!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Run the main GA-optimized prediction system\n",
    "    print(\"Welcome to GA-Optimized LSTM Stock Prediction!\")\n",
    "    print(\"This system uses Genetic Algorithms to find optimal hyperparameters\")\n",
    "    \n",
    "\n",
    "    choice = input(\"\\n Choose mode:\\n1. Interactive prediction with GA\\n2. Quick comparison test\\nEnter choise (1 or 2): \")\n",
    "\n",
    "    if choice == '2':\n",
    "        symbol = input(\"Enter stock symbol for comparison (e.g., AAPL): \").strip().upper()\n",
    "        compare_optimization_methods(symbol)\n",
    "    else:\n",
    "        main_with_ga()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a489c4a5-def3-476b-aaaa-9354339ff34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to GA-Optimized LSTM Stock Prediction!\n",
      "This system uses Genetic Algorithms to find optimal hyperparameters\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " Choose mode:\n",
      "1. Interactive prediction with GA \n",
      "2. Quick comparison test \n",
      "Enter choice (1, or 2):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================\n",
      "GA-OPTIMIZED STOCK PRICE PREDICTION SYSTEM\n",
      "=============================================\n",
      "\n",
      "Select a company to predict:\n",
      "----------------------------------------\n",
      "1 . AAPL  - Apple Inc.\n",
      "2 . GOOGL - Alphabet Inc. (Google)\n",
      "3 . MSFT  - Microsoft Corporation\n",
      "4 . AMZN  - Amazon.com Inc.\n",
      "5 . TSLA  - Tesla Inc.\n",
      "6 . META  - Meta Platforms Inc. (Facebook)\n",
      "7 . NVDA  - NVIDIA Corporation\n",
      "8 . NFLX  - Netflix Inc.\n",
      "9 . JPM   - JPMorgan Chase & Co.\n",
      "10. JNJ   - Johnson & Johnson\n",
      "11. Custom - Enter your own stock symbol\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your choice (1-11):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected: Amazon.com Inc. (AMZN)\n",
      "\n",
      "============================================================\n",
      "GA-OPTIMIZED STOCK PREDICTION FOR Amazon.com Inc. (AMZN)\n",
      "============================================================\n",
      "\n",
      " Optimization Options:\n",
      "1. Use Genetic Algorithm to find best hyperparameters (Recommended, ~10-15 minutes)\n",
      "2. Use default hyperparameters (Fast, ~1 minute)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Choose optimization method (1 or 2):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching data for Amazon.com Inc....\n",
      "Fetching data for AMZN...\n",
      "Last data date: 2025-10-29\n",
      "Predicting price for: 2025-10-30\n",
      "\n",
      "Starting Genetic Algorithm Optimization\n",
      "Population: 12, Generations: 6\n",
      "============================================================\n",
      "\n",
      "Generation 1/6\n",
      "----------------------------------------\n",
      "Individual 1/12\n",
      "Testing: seq_len=60, hidden=100, layers=3, lr=0.0010\n",
      "→ Validation Loss: 0.002411\n",
      "Individual 2/12\n",
      "Testing: seq_len=30, hidden=128, layers=2, lr=0.0020\n",
      "→ Validation Loss: 0.001692\n",
      "Individual 3/12\n",
      "Testing: seq_len=90, hidden=64, layers=4, lr=0.0008\n",
      "→ Validation Loss: 0.002983\n",
      "Individual 4/12\n",
      "Testing: seq_len=80, hidden=142, layers=2, lr=0.0087\n",
      "→ Validation Loss: 0.001399\n",
      "Individual 5/12\n",
      "Testing: seq_len=39, hidden=171, layers=4, lr=0.0010\n",
      "→ Validation Loss: 0.002480\n",
      "Individual 6/12\n",
      "Testing: seq_len=84, hidden=63, layers=2, lr=0.0027\n",
      "→ Validation Loss: 0.002204\n",
      "Individual 7/12\n",
      "Testing: seq_len=49, hidden=75, layers=3, lr=0.0041\n",
      "→ Validation Loss: 0.001902\n",
      "Individual 8/12\n",
      "Testing: seq_len=45, hidden=169, layers=2, lr=0.0050\n",
      "→ Validation Loss: 0.001057\n",
      "Individual 9/12\n",
      "Testing: seq_len=59, hidden=186, layers=4, lr=0.0041\n",
      "→ Validation Loss: 0.019587\n",
      "Individual 10/12\n",
      "Testing: seq_len=29, hidden=126, layers=2, lr=0.0019\n",
      "→ Validation Loss: 0.001309\n",
      "Individual 11/12\n",
      "Testing: seq_len=30, hidden=198, layers=4, lr=0.0015\n",
      "→ Validation Loss: 0.002288\n",
      "Individual 12/12\n",
      "Testing: seq_len=39, hidden=119, layers=4, lr=0.0064\n",
      "→ Validation Loss: 0.001647\n",
      "\n",
      "Generation 1 Results:\n",
      "Best Fitness: 0.001057\n",
      "Average Fitness: 0.003413\n",
      "Time: 5695.8s\n",
      "\n",
      "Generation 2/6\n",
      "----------------------------------------\n",
      "Individual 1/12\n",
      "Testing: seq_len=49, hidden=75, layers=3, lr=0.0041\n",
      "→ Validation Loss: 0.001961\n",
      "Individual 2/12\n",
      "Testing: seq_len=45, hidden=169, layers=2, lr=0.0050\n",
      "→ Validation Loss: 0.001083\n",
      "Individual 3/12\n",
      "Testing: seq_len=80, hidden=126, layers=4, lr=0.0019\n",
      "→ Validation Loss: 0.002017\n",
      "Individual 4/12\n",
      "Testing: seq_len=29, hidden=142, layers=2, lr=0.0087\n",
      "→ Validation Loss: 0.001290\n",
      "Individual 5/12\n",
      "Testing: seq_len=29, hidden=126, layers=2, lr=0.0019\n",
      "→ Validation Loss: 0.001129\n",
      "Individual 6/12\n",
      "Testing: seq_len=45, hidden=169, layers=2, lr=0.0050\n",
      "→ Validation Loss: 0.001042\n",
      "Individual 7/12\n",
      "Testing: seq_len=30, hidden=198, layers=2, lr=0.0019\n",
      "→ Validation Loss: 0.001781\n",
      "Individual 8/12\n",
      "Testing: seq_len=29, hidden=126, layers=4, lr=0.0015\n",
      "→ Validation Loss: 0.001698\n",
      "Individual 9/12\n",
      "Testing: seq_len=29, hidden=126, layers=2, lr=0.0050\n",
      "→ Validation Loss: 0.001061\n",
      "Individual 10/12\n",
      "Testing: seq_len=45, hidden=126, layers=2, lr=0.0019\n",
      "→ Validation Loss: 0.001337\n",
      "Individual 11/12\n",
      "Testing: seq_len=30, hidden=128, layers=2, lr=0.0020\n",
      "→ Validation Loss: 0.001843\n",
      "Individual 12/12\n",
      "Testing: seq_len=30, hidden=128, layers=2, lr=0.0020\n",
      "→ Validation Loss: 0.001859\n",
      "\n",
      "Generation 2 Results:\n",
      "Best Fitness: 0.001042\n",
      "Average Fitness: 0.001508\n",
      "Time: 4170.1s\n",
      "\n",
      "Generation 3/6\n",
      "----------------------------------------\n",
      "Individual 1/12\n",
      "Testing: seq_len=45, hidden=126, layers=2, lr=0.0019\n",
      "→ Validation Loss: 0.001203\n",
      "Individual 2/12\n",
      "Testing: seq_len=45, hidden=169, layers=2, lr=0.0019\n",
      "→ Validation Loss: 0.001101\n",
      "Individual 3/12\n",
      "Testing: seq_len=29, hidden=126, layers=2, lr=0.0024\n",
      "→ Validation Loss: 0.001174\n",
      "Individual 4/12\n",
      "Testing: seq_len=29, hidden=126, layers=2, lr=0.0050\n",
      "→ Validation Loss: 0.001210\n",
      "Individual 5/12\n",
      "Testing: seq_len=45, hidden=169, layers=2, lr=0.0087\n",
      "→ Validation Loss: 0.001321\n",
      "Individual 6/12\n",
      "Testing: seq_len=29, hidden=169, layers=2, lr=0.0050\n",
      "→ Validation Loss: 0.001086\n",
      "Individual 7/12\n",
      "Testing: seq_len=30, hidden=198, layers=2, lr=0.0019\n",
      "→ Validation Loss: 0.001647\n",
      "Individual 8/12\n",
      "Testing: seq_len=29, hidden=126, layers=2, lr=0.0050\n",
      "→ Validation Loss: 0.001288\n",
      "Individual 9/12\n",
      "Testing: seq_len=29, hidden=169, layers=2, lr=0.0050\n",
      "→ Validation Loss: 0.001050\n",
      "Individual 10/12\n",
      "Testing: seq_len=29, hidden=126, layers=2, lr=0.0050\n",
      "→ Validation Loss: 0.001356\n",
      "Individual 11/12\n",
      "Testing: seq_len=45, hidden=126, layers=2, lr=0.0019\n",
      "→ Validation Loss: 0.001297\n",
      "Individual 12/12\n",
      "Testing: seq_len=45, hidden=126, layers=2, lr=0.0019\n",
      "→ Validation Loss: 0.001359\n",
      "\n",
      "Generation 3 Results:\n",
      "Best Fitness: 0.001050\n",
      "Average Fitness: 0.001258\n",
      "Time: 3775.3s\n",
      "\n",
      "Generation 4/6\n",
      "----------------------------------------\n",
      "Individual 1/12\n",
      "Testing: seq_len=45, hidden=169, layers=2, lr=0.0019\n",
      "→ Validation Loss: 0.001120\n",
      "Individual 2/12\n",
      "Testing: seq_len=45, hidden=169, layers=2, lr=0.0050\n",
      "→ Validation Loss: 0.001132\n",
      "Individual 3/12\n",
      "Testing: seq_len=45, hidden=169, layers=2, lr=0.0019\n",
      "→ Validation Loss: 0.001254\n",
      "Individual 4/12\n",
      "Testing: seq_len=29, hidden=169, layers=2, lr=0.0050\n",
      "→ Validation Loss: 0.001214\n",
      "Individual 5/12\n",
      "Testing: seq_len=29, hidden=169, layers=2, lr=0.0050\n",
      "→ Validation Loss: 0.001100\n",
      "Individual 6/12\n",
      "Testing: seq_len=29, hidden=169, layers=2, lr=0.0024\n",
      "→ Validation Loss: 0.001142\n",
      "Individual 7/12\n",
      "Testing: seq_len=29, hidden=169, layers=2, lr=0.0050\n",
      "→ Validation Loss: 0.001079\n",
      "Individual 8/12\n",
      "Testing: seq_len=29, hidden=169, layers=2, lr=0.0050\n",
      "→ Validation Loss: 0.001085\n",
      "Individual 9/12\n",
      "Testing: seq_len=45, hidden=126, layers=2, lr=0.0019\n",
      "→ Validation Loss: 0.001332\n",
      "Individual 10/12\n",
      "Testing: seq_len=45, hidden=169, layers=2, lr=0.0019\n",
      "→ Validation Loss: 0.001319\n",
      "Individual 11/12\n",
      "Testing: seq_len=29, hidden=169, layers=2, lr=0.0050\n",
      "→ Validation Loss: 0.001175\n",
      "Individual 12/12\n",
      "Testing: seq_len=29, hidden=169, layers=2, lr=0.0050\n",
      "→ Validation Loss: 0.001123\n",
      "\n",
      "Generation 4 Results:\n",
      "Best Fitness: 0.001079\n",
      "Average Fitness: 0.001173\n",
      "Time: 5095.8s\n",
      "\n",
      "Early stopping: No significant improvement in last 3 generations\n",
      "\n",
      "GA Optimization Complete!\n",
      "Best Fitness Achieved: 0.001042\n",
      "\n",
      "GENETIC ALGORITHM OPTIMIZATION RESULTS\n",
      "============================================================\n",
      "Best Hyperparameters Found:\n",
      "Sequence Length: 45 days\n",
      "Hidden Size: 169 units\n",
      "Number of Layers: 2\n",
      "Dropout Rate: 0.186\n",
      "Learning Rate: 0.005040\n",
      "Batch Size: 16\n",
      "Epochs: 98\n",
      "Best Validation Loss: 0.001042\n",
      "============================================================\n",
      "\n",
      "Preparing data with 5 features...\n",
      "Training data shape: torch.Size([365, 45, 5])\n",
      "Test data shape: torch.Size([92, 45, 5])\n",
      "\n",
      "Training final model for Amazon.com Inc....\n",
      "Training model...\n",
      "Epoch [20/98], Train Loss: 0.029829, Test Loss: 0.090404\n",
      "Epoch [40/98], Train Loss: 0.008373, Test Loss: 0.002272\n",
      "Epoch [60/98], Train Loss: 0.003925, Test Loss: 0.003563\n",
      "Epoch [80/98], Train Loss: 0.003431, Test Loss: 0.002550\n",
      "Making test predictions...\n",
      "\n",
      "========================================\n",
      "GA-OPTIMIZED STOCK PREDICTION RESULTS\n",
      "========================================\n",
      "\n",
      "COMPANY: Amazon.com Inc. (AMZN)\n",
      "CURRENT PRICE: $230.30\n",
      "PREDICTED NEXT DAY PRICE: $222.23\n",
      "EXPECTED CHANGE: $-8.07 (-3.50%)\n",
      "TREND SIGNAL: 📉 BEARISH\n",
      "\n",
      "MODEL ACCURACY METRICS:\n",
      "Mean Absolute Percentage Error: 2.09%\n",
      "Average Error: $4.69\n",
      "Root Mean Square Error: $5.58\n",
      "Prediction Confidence: HIGH\n",
      "\n",
      " Hyperparameters optimized using Genetic Algorithm\n",
      "\n",
      "================================================================================\n",
      "DISCLAIMER: This prediction is for educational purposes only.\n",
      "Always consult financial advisors before making investment decisions.\n",
      "================================================================================\n",
      "\n",
      "Prediction completed for Amazon.com Inc.!\n",
      "\n",
      "Final Optimized Configuration:\n",
      "sequence_length: 45\n",
      "hidden_size: 169\n",
      "num_layers: 2\n",
      "dropout: 0.1860038044402238\n",
      "learning_rate: 0.005040434443108166\n",
      "batch_size: 16\n",
      "epochs: 98\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Run the main GA-optimized prediction system\n",
    "    print(\"Welcome to GA-Optimized LSTM Stock Prediction!\")\n",
    "    print(\"This system uses Genetic Algorithms to find optimal hyperparameters\")\n",
    "    \n",
    "\n",
    "    choice = input(\"\\n Choose mode:\\n1. Interactive prediction with GA \\n2. Quick comparison test \\nEnter choice (1, or 2): \")\n",
    "\n",
    "    if choice == '2':\n",
    "        symbol = input(\"Enter stock symbol for comparison (e.g., AAPL): \").strip().upper()\n",
    "        compare_optimization_methods(symbol)\n",
    "    else:\n",
    "        main_with_ga()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
